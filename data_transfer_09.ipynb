{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFER STUDY + DOWNWARD ISA STRUCTURE FROM ONE SEEK TO ANOTHER: STUDY, 2X ASSAYS, 2X DATA FILES\n",
    "#                                                         assay -> data_file\n",
    "#                  (project -> investigation) -> study ->\n",
    "#                                                         assay -> data_file\n",
    "\n",
    "# SOURCE SEEK:\n",
    "#    GET/READ/PRINT JSON RESOURCE (ASSAY)    readJsonData()               (session.get)\n",
    "#    FORMAT RELATIONSHIPS                    formatJsonDataRelationships() / formatJsonDataRelationshipsTitle() \n",
    "#    READ DATA FILE BLOB, DOWNLOAD BLOB      readBlobData()(              (session.get, urlopen(Request(url=download_link, headers=headers2)))\n",
    "\n",
    "#    DETERMINE ISA STRUCTURE                 determineISAstructureFromRelationships()\n",
    "#    DETERMINE DOWNWARDS ISA STRUCTURE       getDISA()  \n",
    "#    DETERMINE ALL DOWNWARDS ISA STRUCTURES  getFullDISA()                (from input entry and each of its DISA entries)\n",
    "\n",
    "        \n",
    "# TARGET SEEK: \n",
    "#    REGISTER STUDY                          registerStudy()              (session.post)\n",
    "#    REGISTER ASSAY                          registerAssay()              (session.post)\n",
    "#    REGISTER DATA FILE AND BLOB             registerBlobData()           (session.post)\n",
    "#    UPLOAD BLOB INTO DATA FILE              uploadBlobData()             (session.put)\n",
    "#    COMBINES REGISTER DATA FILE AND UPLOAD BLOB   TransferData()\n",
    "\n",
    "#    REGISTER / UPLOAD STUDY AND BELOW       registerAndCopyStudyAndBelow()\n",
    "#    DELETES THE ISA STRUCTURE               deleteISA()                  \n",
    "\n",
    "\n",
    "# USING 2 SEEKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Import the libraries so that they can be used within the notebook\n",
    "\n",
    "  * **requests** is used to make HTTP calls\n",
    "  * **json** is used to encode and decode strings into JSON\n",
    "  * **string** is used to perform text manipulation and checking\n",
    "  * **pandas** helps format the JSON data in a more readable format\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import string\n",
    "# Importing the libraries we need to format the data in a more readable way. \n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "#authentication\n",
    "import getpass\n",
    "import urllib.request\n",
    "from urllib.request import urlopen, Request\n",
    "from PIL import Image\n",
    "import io\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FUNCTIONS\n",
    "\n",
    "def authenticate(headers):\n",
    "    session = requests.Session()\n",
    "    session.headers.update(headers)\n",
    "    session.auth = (input('Username:'), getpass.getpass('Password')) \n",
    "    return session\n",
    "\n",
    "### GET JSON\n",
    "def json_for_resource(session, headers_json, url, type, id):    \n",
    "  r = session.get(url + \"/\" + type + \"/\" + str(id), headers=headers_json)\n",
    "  if (r.status_code != 200):\n",
    "    print(r.json())\n",
    "  r.raise_for_status()\n",
    "  return r.json()\n",
    "\n",
    "### READ / PRINT JSON\n",
    "def readJsonData(session, headers_json, url, data_id, data_type):\n",
    "    result_json = json_for_resource(session, headers_json, url, data_type, data_id)\n",
    "    filetitle = result_json['data']['attributes']['title']\n",
    "    print(\"Name of \\'\" + data_type + \"\\': \" + filetitle + \"\\n\")\n",
    "    #print(result_json)\n",
    "    return result_json\n",
    "\n",
    "### FORMAT RELATIONSHIPS OF A JSON ([{'type':'data_files', 'id':3, 'title':'New Image'}])\n",
    "def formatJsonDataRelationshipsTitle(session, headers_json, source_base_url, input_data):#, data_types_list\n",
    "    files = []\n",
    "    source_relationships = input_data['data']['relationships']\n",
    "    \n",
    "    for dtype in source_relationships:\n",
    "        #print(dtype)    #data_files, investigation, study, projects\n",
    "        source_dtype_entry = source_relationships[str(dtype)]['data']\n",
    "        \n",
    "        source_data_type = 'none'\n",
    "        source_data_id = 'none'       \n",
    "        \n",
    "        # different formats if plural or singular\n",
    "            #'projects': {'data': [{'id': '2', 'type': 'projects'}]}\n",
    "            #'investigation': {'data': {'id': '3', 'type': 'investigations'}}\n",
    "            #'study': {'data': {'id': '3', 'type': 'studies'}}\n",
    "            #'data_files': {'data': [{'id': '38', 'type': 'data_files'}]}        \n",
    "        \n",
    "        if(dtype=='investigation' or dtype=='study'):#formated differently\n",
    "            item = source_dtype_entry\n",
    "            #print(\"item \", item)\n",
    "            source_data_type = item['type']\n",
    "            source_data_id = item['id']\n",
    "            \n",
    "            j = json_for_resource(session,headers_json,source_base_url,item['type'],item['id'])  \n",
    "            \n",
    "            files.append({\n",
    "                'type':source_data_type, #j['data']['type'],\n",
    "                'id':source_data_id, #j['data']['id'],\n",
    "                'title':j['data']['attributes']['title'],      \n",
    "            })\n",
    "\n",
    "        else:\n",
    "            for item in source_dtype_entry:\n",
    "                #print(\"item \", item)\n",
    "                #print(dtype, \": \", item['type'], item['id'])\n",
    "                \n",
    "                source_data_id = item['id']\n",
    "                source_data_type = item['type']\n",
    "                if(item['type']=='people'): #instead of type 'people', passing submitter, creators etc.\n",
    "                    source_data_type = str(dtype)\n",
    "                \n",
    "                j = json_for_resource(session,headers_json,source_base_url,item['type'],item['id'])  \n",
    "                \n",
    "                files.append({\n",
    "                    'type':source_data_type,\n",
    "                    'id':source_data_id, #j['data']['id'],\n",
    "                    'title':j['data']['attributes']['title'],      \n",
    "                })\n",
    "                \n",
    "\n",
    "        #if(source_data_type != 'none'): print(\"\\t \\t\", dtype, \": \", source_data_type, \"/\", source_data_id)                \n",
    "\n",
    "    print() \n",
    "    print(str(len(files)) + \" relationships found: \\n\") #print(str(len(files)) + \" \\'\" + grep_typep + \"\\' found: \\n\") \n",
    "    print(json_normalize(files)) \n",
    "    return files\n",
    "\n",
    "### FORMAT RELATIONSHIPS OF A JSON ([{'type':'data_files', 'id':3}])\n",
    "def formatJsonDataRelationships(input_data):\n",
    "    files = []\n",
    "    source_relationships = input_data['data']['relationships']\n",
    "    \n",
    "    for dtype in source_relationships:\n",
    "        #print(dtype)    #data_files, investigation, study, projects\n",
    "        source_dtype_entry = source_relationships[str(dtype)]['data']\n",
    "        \n",
    "        source_data_type = 'none'\n",
    "        source_data_id = 'none'       \n",
    "        \n",
    "        # different formats if plural or singular\n",
    "            #'projects': {'data': [{'id': '2', 'type': 'projects'}]}\n",
    "            #'investigation': {'data': {'id': '3', 'type': 'investigations'}}\n",
    "            #'study': {'data': {'id': '3', 'type': 'studies'}}\n",
    "            #'data_files': {'data': [{'id': '38', 'type': 'data_files'}]}        \n",
    "        \n",
    "        if(dtype=='investigation' or dtype=='study'):#formated differently\n",
    "            item = source_dtype_entry\n",
    "            #print(\"item \", item)\n",
    "            source_data_type = item['type']\n",
    "            source_data_id = item['id']\n",
    "            \n",
    "            files.append({\n",
    "                'type':source_data_type, #j['data']['type'],\n",
    "                'id':source_data_id, #j['data']['id'],\n",
    "            })\n",
    "\n",
    "        else:\n",
    "            for item in source_dtype_entry:\n",
    "                #print(\"item \", item)\n",
    "                #print(dtype, \": \", item['type'], item['id'])\n",
    "                \n",
    "                source_data_id = item['id']\n",
    "                source_data_type = item['type']\n",
    "                if(item['type']=='people'): #instead of type 'people', passing submitter, creators etc.\n",
    "                    source_data_type = str(dtype)\n",
    "                \n",
    "                files.append({\n",
    "                    'type':source_data_type,\n",
    "                    'id':source_data_id, #j['data']['id'],\n",
    "                })\n",
    "                \n",
    "\n",
    "        #if(source_data_type != 'none'): print(\"\\t \\t\", dtype, \": \", source_data_type, \"/\", source_data_id)                \n",
    "\n",
    "    print() \n",
    "    print(str(len(files)) + \" relationships found: \\n\") #print(str(len(files)) + \" \\'\" + grep_typep + \"\\' found: \\n\") \n",
    "    print(json_normalize(files)) \n",
    "    return files\n",
    "\n",
    "### READ DATA_FILE DATA, GET BLOB DATA\n",
    "def readBlobData(session, headers_json, headers_token, url, data_id, data_type):\n",
    "    result_json = json_for_resource(session, headers_json, url, data_type, data_id)#uses session\n",
    "    \n",
    "    filetitle = result_json['data']['attributes']['title']\n",
    "    #print(\"Name of \\'\" + data_type + \"\\': \" + filetitle + \"\\n\")\n",
    "    #print(\"Policy: \", result_json['data']['attributes']['policy'],\"\\n\")\n",
    "    filelicense = result_json['data']['attributes']['license']\n",
    "    \n",
    "    blob = result_json['data']['attributes']['content_blobs'][0]\n",
    "    #print(\"Blob: \", blob,\"\\n\")\n",
    "    \n",
    "    filename = blob['original_filename']\n",
    "    filetype = blob['content_type']\n",
    "\n",
    "    \n",
    "    link = blob['link']\n",
    "    download_link = link + \"/download\"\n",
    "    #print(\"Download link is: \" + download_link)\n",
    "    \n",
    "    #get blob data\n",
    "    #response = urllib.request.urlopen(download_link)\n",
    "    ###from urllib.request import urlopen, Request\n",
    "    req = Request(url=download_link, headers=headers_token) \n",
    "    data = urlopen(req).read()\n",
    "    \n",
    "    #data = response.read()\n",
    "    #print(response)\n",
    "    #print(data)\n",
    "    return result_json, filetitle, filename, filetype, filelicense, link, download_link, data\n",
    "\n",
    "###############################################################\n",
    "\n",
    "\n",
    "### REGISTER STUDY\n",
    "def registerStudy(session, in_study_json, target_project_id, target_investigation_id, target_creator_id):\n",
    "    new_study_json = {}\n",
    "    new_study_json['data'] = {}\n",
    "    new_study_json['data']['type'] = 'studies'\n",
    "\n",
    "    new_study_json['data']['attributes'] = {}\n",
    "    new_study_json['data']['attributes']['title'] = in_study_json['data']['attributes']['title']\n",
    "    new_study_json['data']['attributes']['description'] = in_study_json['data']['attributes']['description']\n",
    "\n",
    "    #new_assay_json['data']['attributes']['policy'] = in_assay_json['data']['attributes']['policy']\n",
    "    new_study_json['data']['attributes']['policy'] = {'access':'no_access'}\n",
    "    new_study_json['data']['attributes']['policy']['permissions'] = [{'resource':{'id':target_project_id,'type':'projects'},'access':'download'}];\n",
    "\n",
    "    #new_assay_json['data']['attributes']['assay_class'] = in_assay_json['data']['attributes']['assay_class']\n",
    "    #new_assay_json['data']['attributes']['assay_type'] = in_assay_json['data']['attributes']['assay_type']\n",
    "    #new_assay_json['data']['attributes']['technology_type'] = in_assay_json['data']['attributes']['technology_type']\n",
    "\n",
    "    new_study_json['data']['relationships'] = {}\n",
    "    new_study_json['data']['relationships']['creators'] = {}\n",
    "    new_study_json['data']['relationships']['creators']['data'] = [{'id' : target_creator_id, 'type' : 'people'}]\n",
    "    #new_study_json['data']['relationships']['study'] = {}\n",
    "    #new_study_json['data']['relationships']['study']['data'] = {'id' : target_study_id, 'type' : 'studies'}\n",
    "    new_study_json['data']['relationships']['investigation'] = {}\n",
    "    new_study_json['data']['relationships']['investigation']['data'] = {'id' : target_investigation_id, 'type' : 'investigations'}\n",
    "    new_study_json['data']['relationships']['projects'] = {}\n",
    "    new_study_json['data']['relationships']['projects']['data'] = {'id' : target_project_id, 'type' : 'projects'}\n",
    "\n",
    "    r = session.post(target_base_url + '/studies', json=new_study_json)\n",
    "    r.raise_for_status()\n",
    "    populated_study = r.json()\n",
    "    print(\"Registered study: \", populated_study)   \n",
    "    study_id = populated_study['data']['id']\n",
    "    \n",
    "    return new_study_json, study_id\n",
    "\n",
    "\n",
    "### REGISTER ASSAY\n",
    "def registerAssay(session, in_assay_json, target_project_id, target_investigation_id, target_study_id, target_creator_id):\n",
    "    new_assay_json = {}\n",
    "    new_assay_json['data'] = {}\n",
    "    new_assay_json['data']['type'] = 'assays'\n",
    "\n",
    "    new_assay_json['data']['attributes'] = {}\n",
    "    new_assay_json['data']['attributes']['title'] = in_assay_json['data']['attributes']['title']\n",
    "    new_assay_json['data']['attributes']['description'] = in_assay_json['data']['attributes']['description']\n",
    "\n",
    "    #new_assay_json['data']['attributes']['policy'] = in_assay_json['data']['attributes']['policy']\n",
    "    new_assay_json['data']['attributes']['policy'] = {'access':'no_access'}\n",
    "    new_assay_json['data']['attributes']['policy']['permissions'] = [{'resource':{'id':target_project_id,'type':'projects'},'access':'download'}];\n",
    "\n",
    "    new_assay_json['data']['attributes']['assay_class'] = in_assay_json['data']['attributes']['assay_class']\n",
    "    new_assay_json['data']['attributes']['assay_type'] = in_assay_json['data']['attributes']['assay_type']\n",
    "    new_assay_json['data']['attributes']['technology_type'] = in_assay_json['data']['attributes']['technology_type']\n",
    "\n",
    "    new_assay_json['data']['relationships'] = {}\n",
    "    new_assay_json['data']['relationships']['creators'] = {}\n",
    "    new_assay_json['data']['relationships']['creators']['data'] = [{'id' : target_creator_id, 'type' : 'people'}]\n",
    "    new_assay_json['data']['relationships']['study'] = {}\n",
    "    new_assay_json['data']['relationships']['study']['data'] = {'id' : target_study_id, 'type' : 'studies'}\n",
    "    new_assay_json['data']['relationships']['investigation'] = {}\n",
    "    new_assay_json['data']['relationships']['investigation']['data'] = {'id' : target_investigation_id, 'type' : 'investigations'}\n",
    "    new_assay_json['data']['relationships']['projects'] = {}\n",
    "    new_assay_json['data']['relationships']['projects']['data'] = {'id' : target_project_id, 'type' : 'projects'}\n",
    "\n",
    "    r = session.post(target_base_url + '/assays', json=new_assay_json)\n",
    "    r.raise_for_status()\n",
    "    populated_assay = r.json()\n",
    "    print(\"Registered assay: \", populated_assay)   \n",
    "    assay_id = populated_assay['data']['id']\n",
    "    \n",
    "    return assay_id\n",
    "\n",
    "\n",
    "### REGISTER DATA FILE AND BLOB \n",
    "def registerBlobData(session, base_url, data_type, filetitle, filelicense, blob, target_project_id, target_investigation_id, target_study_id, target_assay_id, target_creator_id):\n",
    "    data_array_name = {}\n",
    "    data_array_name['data'] = {}\n",
    "    data_array_name['data']['type'] = data_type\n",
    "    \n",
    "    data_array_name['data']['attributes'] = {}\n",
    "    data_array_name['data']['attributes']['title'] = filetitle\n",
    "    data_array_name['data']['attributes']['license'] = filelicense #'CC-BY-4.0'\n",
    "    #data_array_name['data']['attributes']['policy'] = {'access':'download'}\n",
    "    data_array_name['data']['attributes']['policy'] = {'access':'no_access'}\n",
    "    data_array_name['data']['attributes']['policy']['permissions'] = [{'resource':{'id':target_project_id,'type':'projects'},'access':'download'}];\n",
    "    data_array_name['data']['attributes']['content_blobs'] = [blob] #error if blob is not there\n",
    "        \n",
    "    data_array_name['data']['relationships'] = {}\n",
    "    data_array_name['data']['relationships']['projects'] = {}\n",
    "    data_array_name['data']['relationships']['projects']['data'] = [{'id' : target_project_id, 'type' : 'projects'}]\n",
    "    data_array_name['data']['relationships']['investigations'] = {}\n",
    "    data_array_name['data']['relationships']['investigations']['data'] = [{'id' : target_investigation_id, 'type' : 'investigations'}]\n",
    "    data_array_name['data']['relationships']['studies'] = {}\n",
    "    data_array_name['data']['relationships']['studies']['data'] = [{'id' : target_study_id, 'type' : 'studies'}]\n",
    "    data_array_name['data']['relationships']['assays'] = {}\n",
    "    data_array_name['data']['relationships']['assays']['data'] = [{'id' : target_assay_id, 'type' : 'assays'}]\n",
    "    data_array_name['data']['relationships']['creators'] = {}\n",
    "    data_array_name['data']['relationships']['creators']['data'] = [{'id' : target_creator_id, 'type' : 'people'}]\n",
    "    \n",
    "    #register data file\n",
    "    r = session.post(base_url + '/' + data_type, json = data_array_name)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    populated_data_file = r.json()\n",
    "    print(\"Registered data_file: \", populated_data_file[\"data\"])\n",
    "    #print(\"Registered json:\")\n",
    "    data_file_id = populated_data_file[\"data\"]['id']\n",
    "    data_file_link = populated_data_file['data']['attributes']['content_blobs'][0]['link']  \n",
    "\n",
    "    \n",
    "    return data_file_id, data_file_link\n",
    "\n",
    "\n",
    "### UPLOAD BLOB INTO DATA FILE\n",
    "def uploadBlobData(session, headers_json, headers_stream, base_url, data_type, blob_id, blob_url, binary_data):\n",
    "\n",
    "    #get url from json content blob\n",
    "    #blob_url = registered_json_data['data']['attributes']['content_blobs'][0]['link']    \n",
    " \n",
    "    #PUT data\n",
    "    upload = session.put(blob_url, data = binary_data, headers = headers_stream)\n",
    "    upload.raise_for_status()\n",
    "    \n",
    "    #print content blob\n",
    "    #blob_id = registered_json_data['data']['id']  \n",
    "    created_json = json_for_resource(session, headers_json, base_url, data_type, blob_id)\n",
    "    print(\"Uploaded blob data: \", created_json['data']['attributes']['content_blobs'])\n",
    "    \n",
    "        \n",
    "### COMBINES REGISTER DATA FILE AND UPLOAD BLOB (not needed)\n",
    "def TransferData(session, headers_json, headers_stream, base_url, data_type, filetitle, filelicense, blob, dataBinary,\n",
    "    target_project_id, target_investigation_id, target_study_id, target_assay_id, target_creator_id): # register, upload\n",
    "    #registered_json_data = registerBlobData(session, base_url, data_type, filetitle, blob)\n",
    "    #uploadBlobData(session, base_url, data_type, registered_json_data, dataBinary)\n",
    "    \n",
    "    #target_data_file  = registerBlobData(\n",
    "    #    session2, target_base_url, target_data_file_data_type, target_filetitle, target_filelicense, target_blob, \n",
    "    #    target_project_id, target_investigation_id, target_study_id, target_assay_id, target_creator_id2)\n",
    "    #target_data_file_id = target_data_file[0]\n",
    "    #target_data_file_link = target_data_file[1]\n",
    "    \n",
    "    #uploadBlobData(session2, headers3, target_base_url, target_data_file_data_type, target_data_file_id, target_data_file_link, dataBinary)\n",
    "    \n",
    "    target_data_file  = registerBlobData(\n",
    "        session, base_url, data_type, filetitle, filelicense, blob, \n",
    "        target_project_id, target_investigation_id, target_study_id, target_assay_id, target_creator_id)\n",
    "    target_data_file_id = target_data_file[0]\n",
    "    target_data_file_link = target_data_file[1]\n",
    "    \n",
    "    print()\n",
    "    uploadBlobData(session, headers_json, headers_stream, base_url, data_type, target_data_file_id, target_data_file_link, dataBinary)      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AUTHENTICATION\n",
    "API_TOKEN = open(\"token\").readline().strip() #\"user:password\" encoded in base64\n",
    "\n",
    "headers1 = { #headers_json\n",
    "        \"Accept\": \"application/vnd.api+json\", \n",
    "        \"Content-type\": \"application/vnd.api+json\",\n",
    "        \"Accept-Charset\": \"ISO-8859-1\" \n",
    "           } \n",
    "\n",
    "headers2 = { #headers_token\n",
    "        \"Authorization\": \"Basic %s\" %API_TOKEN,\n",
    "        #'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
    "        \"Accept\": \"application/vnd.api+json\", #'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "        \"Content-type\": \"application/vnd.api+json\",\n",
    "        \"Accept-Charset\": \"ISO-8859-1\" #'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "        #'Accept-Encoding': 'none',\n",
    "        #'Accept-Language': 'en-US,en;q=0.8',\n",
    "        #'Connection': 'keep-alive'\n",
    "           }\n",
    "\n",
    "headers3 = { #headers_stream\n",
    "        \"Authorization\": \"Basic %s\" %API_TOKEN,    \n",
    "        \"Accept\": \"application/octet-stream\",\n",
    "        \"Content-Type\": \"application/octet-stream\"\n",
    "           } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# SOURCE SEEK #######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username:dudasda\n",
      "Password········\n"
     ]
    }
   ],
   "source": [
    "session1 = authenticate(headers1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SOURCE DATA PARAMETERS\n",
    "\n",
    "source_base_url = 'http://localhost:3000'\n",
    "\n",
    "########### ISA structure ########\n",
    "#### project \n",
    "#source_project_id = 2      # Project Alpha\n",
    "#source_data_type = 'projects'\n",
    "\n",
    "### data file (with Project Alpha)\n",
    "#source_data_id = 35 # Network Image                \n",
    "#source_data_type = 'data_files'\n",
    "\n",
    "### data file (with Project Alpha) (also in Default Project)\n",
    "#source_data_id = 1 # Pink Test Image               \n",
    "#source_data_type = 'data_files'\n",
    "\n",
    "#### investigation (with Project Alpha)\n",
    "#source_investigation_id = 3 # investigation one\n",
    "#source_data_type = 'investigations'\n",
    "#source_data_type_alt = 'investigation'\n",
    "\n",
    "#### study (with investigation one)\n",
    "source_study_id = 3 # study one\n",
    "source_data_type = 'studies'    \n",
    "#source_data_type_alt = 'study'\n",
    "    \n",
    "#### assay (with study one) \n",
    "#source_assay_id = 3 # assay linked to data file\n",
    "#source_data_type = 'assays'\n",
    "\n",
    "### data file (with \"assay linked to data file\")  \n",
    "#source_data_id = 4 # New Pink Image                \n",
    "#source_data_type = 'data_files'\n",
    "\n",
    "#### assay (with study one) \n",
    "#source_assay_id = 4 # Assay to be copied\n",
    "#source_data_type = 'assays'\n",
    "\n",
    "### data file (with \"Assay to be copied\") \n",
    "#source_data_id = 38 # Network Image                \n",
    "#source_data_type = 'data_files'\n",
    "\n",
    "\n",
    "### people (with Project Alpha)\n",
    "#source_person_id = 1 # Dorotea Dudas                \n",
    "#source_data_type = 'creators'\n",
    "#source_data_type_alt = 'creator'\n",
    "\n",
    "### people (with Default Project)\n",
    "#source_person_id = 3 # Teodora Dudas                \n",
    "#source_data_type = 'creators'\n",
    "#source_data_type_alt = 'creator'\n",
    "\n",
    "source_json_id = source_study_id\n",
    "#source_json_id = source_investigation_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### GET/READ/PRINT JSON RESOURCE (ASSAY)\n",
    "#source_json = readJsonData(session1, headers1, source_base_url, source_json_id, source_data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FORMAT RELATIONSHIPS OF A JSON \n",
    "#source_relationships = formatJsonDataRelationshipsTitle(session1, headers1, source_base_url, source_json)\n",
    "##source_relationships = formatJsonDataRelationships(source_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ISA STRUCTURE (takes in input data type and formatted relationships ([{'type':'data_files', 'id':3}]))\n",
    "### defines the hierarchy of the data types\n",
    "def determineISAstructureFromRelationships(data_type, input_relationships):\n",
    "    #print(input_relationships)\n",
    "    \n",
    "    #ISA structure\n",
    "    #print();print(\"ISA STRUCTURE: \")\n",
    "    structure = ['projects', 'investigations', 'studies', 'assays', 'data_files'] # investigation, study\n",
    "    \n",
    "    structure_up = []\n",
    "    structure_down = []\n",
    "    structure_people = ['creators', 'submitter', 'people'] # creator?\n",
    "    \n",
    "    isa_structure_up = []\n",
    "    isa_structure_down = []  \n",
    "    isa_structure_people = []    \n",
    "    \n",
    "    if(data_type == 'projects'):\n",
    "        structure_up = [] \n",
    "        structure_down = ['investigations', 'studies', 'assays', 'data_files'] \n",
    "    if(data_type == 'investigations'):\n",
    "        structure_up = ['projects'] \n",
    "        structure_down = ['studies', 'assays', 'data_files']         \n",
    "    if(data_type == 'studies'):\n",
    "        structure_up = ['projects', 'investigations'] # investigation\n",
    "        structure_down = ['assays', 'data_files'] \n",
    "    if(data_type == 'assays'):\n",
    "        structure_up = ['projects', 'investigations', 'studies'] # investigation, study\n",
    "        structure_down = ['data_files'] \n",
    "    if(data_type == 'data_files'):\n",
    "        structure_up = ['projects', 'investigations', 'studies', 'assays']\n",
    "        structure_down = []   \n",
    "    \n",
    "    for item in input_relationships:\n",
    "        for y in range(0, len(structure_up)):\n",
    "            if(item['type']==structure_up[y]):\n",
    "                isa_structure_up.append(item)  \n",
    "        for y in range(0, len(structure_down)):\n",
    "            if(item['type']==structure_down[y]):\n",
    "                isa_structure_down.append(item) \n",
    "        for y in range(0, len(structure_people)):\n",
    "            #if(source_data_type==structure_people[y]):\n",
    "            #if(dtype==structure_people[y]):\n",
    "            if(item['type']==structure_people[y]):\n",
    "                isa_structure_people.append(item)              \n",
    "             \n",
    "    #print()\n",
    "    #print(json_normalize(isa_structure))\n",
    "    if(len(isa_structure_up)>0):\n",
    "        print(\"ISA STRUCTURE UP:\");print(json_normalize(isa_structure_up));print()\n",
    "    if(len(isa_structure_down)>0):        \n",
    "        print(\"ISA STRUCTURE DOWN:\");print(json_normalize(isa_structure_down));print()\n",
    "    if(len(isa_structure_people)>0): \n",
    "        print(\"ISA STRUCTURE PEOPLE:\");print(json_normalize(isa_structure_people));print()\n",
    "        \n",
    "    #return isa_structure\n",
    "    return isa_structure_up, isa_structure_down, isa_structure_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ISA STRUCTURE\n",
    "#isas = determineISAstructureFromRelationships(source_data_type,source_relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GET DISA (DOWNWARDS ISA STRUCTURE)\n",
    "def getDISA(session, headers_json, url, data_id, data_type): #uses: readJsonData(), formatJsonDataRelationshipsTitle(), determineISAstructureFromRelationships()\n",
    "\n",
    "    ### READ JSON FILE\n",
    "    print(\"FILE: \")\n",
    "    source_json = readJsonData(session, headers_json, url, data_id, data_type)\n",
    "    #print(source_json['data']['relationships'])\n",
    "    \n",
    "    ### FORMAT RELATIONSHIPS\n",
    "    print(\"RELATIONSHIPS: \")\n",
    "    source_relationships = formatJsonDataRelationshipsTitle(session, headers_json, url, source_json)\n",
    "    #source_relationships = formatJsonDataRelationships(source_json)\n",
    "    \n",
    "    ### DETERMINE DISA\n",
    "    print();print(\"ISA STRUCTURE: \")\n",
    "    isas = determineISAstructureFromRelationships(data_type, source_relationships)\n",
    "    \n",
    "    return isas[1]#isa_structure_down (DISA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### GET DISA (DOWNWARDS ISA STRUCTURE)\n",
    "#out = getDISA(session1, headers1, source_base_url, source_json_id, source_data_type)\n",
    "#print(\"OUTPUT:\\n\", json_normalize(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GET DISA OF THE ORIGINAL JSON ENTRY AND OF EACH OF ITS RESULT ENTRIES\n",
    "\n",
    "# 1st element is the intial entry\n",
    "#   [intial entry e.g. study, [list of its downwards isa structure]]\n",
    "#   [1st element of downwards ISA, [list of its downwards isa structure]]\n",
    "#   ...\n",
    "#   [last element of downwards ISA, [list of its downwards isa structure]]\n",
    "\n",
    "def getFullDISA(session1, headers1, source_base_url, source_json_id, source_data_type):#uses: getDISA()\n",
    "    ### ISA STRUCTURE OF THE INITAL FILE\n",
    "    out = getDISA(session1, headers1, source_base_url, source_json_id, source_data_type)\n",
    "    \n",
    "    ### GET THE ISA STRUCTURE OF EACH ENTRY FROM 'out' (ISA STRUCTURE OF THE INITAL FILE)\n",
    "    isa_struct = []\n",
    "    isa_struct.append([{'type': source_data_type, 'id': source_json_id}, out])\n",
    "    for entry_num in range(0, len(out)):\n",
    "        out_temp = getDISA(session1, headers1, source_base_url, out[entry_num]['id'], out[entry_num]['type'])\n",
    "        #also checking the DISA for data_files, just to not omit anything (not likely that they have any)\n",
    "        if(len(out_temp)>0):#if there is a DISA\n",
    "            print(\"OUTPUT:\\n\", json_normalize(out_temp),\"\\n\")\n",
    "            isa_struct.append([out[entry_num], out_temp])\n",
    "        else:\n",
    "            out_temp = [];\n",
    "            print(\"OUTPUT: empty \\n\")  \n",
    "            isa_struct.append([out[entry_num], out_temp])\n",
    "            \n",
    "    return isa_struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GET DISA OF THE ORIGINAL JSON ENTRY AND OF EACH OF ITS RESULT ENTRIES\n",
    "#isa_structure = getFullDISA(session1, headers1, source_base_url, source_json_id, source_data_type);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# TARGET SEEK #######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username:dudasda\n",
      "Password········\n"
     ]
    }
   ],
   "source": [
    "session2 = authenticate(headers1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TARGET DATA PARAMETERS (ENTRY POINT FOR COPYING)\n",
    "\n",
    "### DATABASE\n",
    "#target_base_url = 'http://localhost:4000'\n",
    "target_base_url = 'http://doroteadesktop:4000'\n",
    "\n",
    "### TARGET PROJECT\n",
    "target_project_id = 2 # Project Alpha\n",
    "target_project_type = 'projects'\n",
    "\n",
    "### TARGET INVESTIGATION\n",
    "target_investigation_id = 4 # investigation two\n",
    "target_investigation_data_type = 'investigatons'\n",
    "\n",
    "### PEOPLE (THIS IS NOT RESOLVED NICELY YET, SO FOR NOW JUST SETTING NOT COPYING)\n",
    "target_creator_id = 1      # Dorotea           (same id as source seek, since they are originaly clones)\n",
    "#target_creator_id2 = 3    # Teodora           (same id as source seek, since they are originaly clones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### REGISTER THE ISA STRUCTURE DOWN (DISA) IN THE TARGET DATABASE AND COPY DATA\n",
    "### uses: getFullDISA() -> getDISA() -> readJsonData(), formatJsonDataRelationshipsTitle(), determineISAstructureFromRelationships()\n",
    "### uses: readJsonData(), registerStudy(), \n",
    "### uses: readJsonData(), registerAssay(),\n",
    "### uses: readBlobData(), registerBlobData(), uploadBlobData()\n",
    "def registerAndCopyStudyAndBelow(session1, session2, headers1, headers2, headers3, \n",
    "                                 source_base_url, source_json_id, source_data_type, #source_json, \n",
    "                                 target_base_url, target_project_id, target_investigation_id, target_creator_id):#isa_structure\n",
    "    \n",
    "    ### GET DOWNWARD ISA STRUCTURE\n",
    "    isa_structure = getFullDISA(session1, headers1, source_base_url, source_json_id, source_data_type)    \n",
    "\n",
    "    ### READ SOURCE JSON\n",
    "    source_json = readJsonData(session1, headers1, source_base_url, source_json_id, source_data_type)\n",
    "    \n",
    "    ### PEOPLE need to be improved later\n",
    "    #target_creator_id = 1      # Dorotea           (same id as source seek, since they are originaly clones)   \n",
    "    \n",
    "    ### REGISTER TARGET JSON (STUDY) \n",
    "    out_json = registerStudy(session2, source_json, target_project_id, target_investigation_id, target_creator_id)#out_json[0] - json   ;  #out_json[1] - id\n",
    "    target_study_id = out_json[1]\n",
    "    \n",
    "    ### FORMAT OF isa_structure\n",
    "        #print(\"study:\", isa_structure[0][0])    # study entry\n",
    "        #print(\"DISA study 1st entry: \",isa_structure[0][1][0]) # 1st entry of the list\n",
    "        ##print(\"DISA study 1st entry: \",isa_structure[0][1][0]['type']) \n",
    "        ##print(\"DISA study 1st entry: \",isa_structure[0][1][0]['id']) \n",
    "        ##print(\"DISA study 1st entry: \",isa_structure[0][1][0]['title'])\n",
    "        #print(\"DISA study 2nd entry: \",isa_structure[0][1][1]) # 1st entry of the list\n",
    "        #print(\"DISA study 3rd entry: \",isa_structure[0][1][2]) # 1st entry of the list\n",
    "        #print(\"DISA study 4th entry: \",isa_structure[0][1][3]) # 1st entry of the list\n",
    "        #print()\n",
    "        ##print(\"DISA study 1st entry + its DISA \", isa_structure[1])\n",
    "        #print(\"DISA study 1st entry: \", isa_structure[1][0])# assay entry\n",
    "        ##print(\"DISA of DISA study list: \", isa_structure[1][1])# its downwards ISA list\n",
    "        #print(\"DISA of DISA study 1st entry: \", isa_structure[1][1][0])# 1st entry of the list\n",
    "        #print()\n",
    "        #print(\"DISA study 2nd entry: \", isa_structure[2][0])# assout_json[1]ay entry\n",
    "        #print(\"DISA of DISA study 2nd entry: \", isa_structure[2][1][0])# 1st entry of the list\n",
    "        #print()\n",
    "        #print(\"DISA study 3rd entry: \", isa_structure[3][0])# image entry\n",
    "        #print(\"DISA of DISA study 3rd entry: \", isa_structure[3][1])# 1st entry of the list (empty, so no 1st element)\n",
    "        #print()\n",
    "        #print(\"DISA study 4th entry: \", isa_structure[4][0])# image entry\n",
    "        #print(\"DISA of DISA study 4th entry: \", isa_structure[4][1])# 1st entry of the list (empty, so no 1st element)    \n",
    "        ### OUTPUT\n",
    "        #isa_structure[0][0]    study: {'type': 'studies', 'id': 3}\n",
    "        #isa_structure[0][1][0] DISA study 1st entry:  {'type': 'assays', 'id': '3', 'title': 'assay linked to data file'}\n",
    "        #isa_structure[0][1][1] DISA study 2nd entry:  {'type': 'assays', 'id': '4', 'title': 'Assay to be copied'}\n",
    "        #isa_structure[0][1][2] DISA study 3rd entry:  {'type': 'data_files', 'id': '4', 'title': 'New Pink Image'}\n",
    "        #isa_structure[0][1][3] DISA study 4th entry:  {'type': 'data_files', 'id': '38', 'title': 'Network Image'}\n",
    "        #isa_structure[1][0]    DISA study 1st entry:  {'type': 'assays', 'id': '3', 'title': 'assay linked to data file'}\n",
    "        #isa_structure[1][1][0] DISA of DISA study 1st entry:  {'type': 'data_files', 'id': '4', 'title': 'New Pink Image'}\n",
    "        #isa_structure[2][0]    DISA study 2nd entry:  {'type': 'assays', 'id': '4', 'title': 'Assay to be copied'}\n",
    "        #isa_structure[2][1][0] DISA of DISA study 2nd entry:  {'type': 'data_files', 'id': '38', 'title': 'Network Image'}\n",
    "        #isa_structure[3][0]    DISA study 3rd entry:  {'type': 'data_files', 'id': '4', 'title': 'New Pink Image'}\n",
    "        #isa_structure[3][1]    DISA of DISA study 3rd entry:  []\n",
    "        #isa_structure[4][0]    DISA study 4th entry:  {'type': 'data_files', 'id': '38', 'title': 'Network Image'}\n",
    "        #isa_structure[4][1]    DISA of DISA study 4th entry:  []    \n",
    "\n",
    "    ### GO THROUGH DISA - READ, REGISTER, UPLOAD   (isa_structure[0][1][x] (from 0) or isa_structure[x][0] (from 1))\n",
    "    ### ASSAYS -> DATA_FILES\n",
    "    if(len(isa_structure)>1):# if there is DISA (1st one is the initial source json)\n",
    "        for x in range(0, len(isa_structure)):# go through DISA  \n",
    "            if(isa_structure[x][0]['type']=='assays'):# if it is an assay\n",
    "                \n",
    "                ### READ JSON\n",
    "                assay_json = readJsonData(session1, headers1, source_base_url, isa_structure[x][0]['id'], isa_structure[x][0]['type'])\n",
    "                \n",
    "                ### REGISTER ASSAY (in second seek and get the id)\n",
    "                target_assay_id = registerAssay(session2, assay_json, target_project_id, target_investigation_id, target_study_id, target_creator_id)\n",
    "            \n",
    "                ### CHECK ASSAY DISA (see which data file goes to which assay from isa_structure)\n",
    "                if(len(isa_structure[x][1])>0):#if there is a downwards structure of the assay\n",
    "                    for y in range(0, len(isa_structure[x][1])):#go through each element\n",
    "                        #isa_structure[x][1][y]['type']\n",
    "                        #isa_structure[x][1][y]['id']\n",
    "                        if(isa_structure[x][1][y]['type']=='data_files'):#if it is a data file\n",
    "                            \n",
    "                            ### READ DATA FILE BLOB FROM SOURCE\n",
    "                            dataRead = readBlobData(session1, headers1, headers2, source_base_url, isa_structure[x][1][y]['id'], 'data_files')\n",
    "                            \n",
    "                            dataBinary = dataRead[7]\n",
    "                            #target_data_file_id - will be obtained after registering a data_file\n",
    "                            #target_data_file_data_type = 'data_files'\n",
    "                            target_filetitle = dataRead[1]\n",
    "                            target_filelicense = dataRead[4]\n",
    "                            # data_file blob\n",
    "                            target_filename = dataRead[2]\n",
    "                            target_filetype = dataRead[3]\n",
    "                            target_blob = {'original_filename' : target_filename, 'content_type' : target_filetype}           \n",
    "                   \n",
    "                            ### REGISTER DATA FILE AND BLOB TO TARGET SEEK\n",
    "                            target_data_file  = registerBlobData(session2, target_base_url, 'data_files', target_filetitle, target_filelicense, target_blob, \n",
    "                                                                 target_project_id, target_investigation_id, target_study_id, target_assay_id, target_creator_id)    \n",
    "                            target_data_file_id = target_data_file[0]\n",
    "                            target_data_file_link = target_data_file[1]\n",
    "                   \n",
    "                            ### UPLOAD BLOB INTO DATA FILE IN TARGET DATABASE\n",
    "                            uploadBlobData(session2, headers1, headers3, target_base_url, 'data_files', target_data_file_id, target_data_file_link, dataBinary)\n",
    "                        \n",
    "                            ### COMBINES REGISTER DATA FILE AND UPLOAD BLOB\n",
    "                            #TransferData(session2, headers1, headers3, target_base_url, 'data_files', \n",
    "                            #             target_filetitle, target_filelicense, target_blob, dataBinary, \n",
    "                            #             target_project_id, target_investigation_id, target_study_id, target_assay_id, target_creator_id)\n",
    "\n",
    "    print(\"DONE\")                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE: \n",
      "Name of 'studies': study one\n",
      "\n",
      "RELATIONSHIPS: \n",
      "\n",
      "8 relationships found: \n",
      "\n",
      "   id                      title            type\n",
      "0   1              Dorotea Dudas       submitter\n",
      "1   1              Dorotea Dudas          people\n",
      "2   2              Project Alpha        projects\n",
      "3   3          investigation one  investigations\n",
      "4   3  assay linked to data file          assays\n",
      "5   4         Assay to be copied          assays\n",
      "6   4             New Pink Image      data_files\n",
      "7  38              Network Image      data_files\n",
      "\n",
      "ISA STRUCTURE: \n",
      "ISA STRUCTURE UP:\n",
      "  id              title            type\n",
      "0  2      Project Alpha        projects\n",
      "1  3  investigation one  investigations\n",
      "\n",
      "ISA STRUCTURE DOWN:\n",
      "   id                      title        type\n",
      "0   3  assay linked to data file      assays\n",
      "1   4         Assay to be copied      assays\n",
      "2   4             New Pink Image  data_files\n",
      "3  38              Network Image  data_files\n",
      "\n",
      "ISA STRUCTURE PEOPLE:\n",
      "  id          title       type\n",
      "0  1  Dorotea Dudas  submitter\n",
      "1  1  Dorotea Dudas     people\n",
      "\n",
      "FILE: \n",
      "Name of 'assays': assay linked to data file\n",
      "\n",
      "RELATIONSHIPS: \n",
      "\n",
      "6 relationships found: \n",
      "\n",
      "  id              title            type\n",
      "0  1      Dorotea Dudas       submitter\n",
      "1  1      Dorotea Dudas          people\n",
      "2  2      Project Alpha        projects\n",
      "3  3  investigation one  investigations\n",
      "4  3          study one         studies\n",
      "5  4     New Pink Image      data_files\n",
      "\n",
      "ISA STRUCTURE: \n",
      "ISA STRUCTURE UP:\n",
      "  id              title            type\n",
      "0  2      Project Alpha        projects\n",
      "1  3  investigation one  investigations\n",
      "2  3          study one         studies\n",
      "\n",
      "ISA STRUCTURE DOWN:\n",
      "  id           title        type\n",
      "0  4  New Pink Image  data_files\n",
      "\n",
      "ISA STRUCTURE PEOPLE:\n",
      "  id          title       type\n",
      "0  1  Dorotea Dudas  submitter\n",
      "1  1  Dorotea Dudas     people\n",
      "\n",
      "OUTPUT:\n",
      "   id           title        type\n",
      "0  4  New Pink Image  data_files \n",
      "\n",
      "FILE: \n",
      "Name of 'assays': Assay to be copied\n",
      "\n",
      "RELATIONSHIPS: \n",
      "\n",
      "7 relationships found: \n",
      "\n",
      "   id              title            type\n",
      "0   1      Dorotea Dudas        creators\n",
      "1   1      Dorotea Dudas       submitter\n",
      "2   1      Dorotea Dudas          people\n",
      "3   2      Project Alpha        projects\n",
      "4   3  investigation one  investigations\n",
      "5   3          study one         studies\n",
      "6  38      Network Image      data_files\n",
      "\n",
      "ISA STRUCTURE: \n",
      "ISA STRUCTURE UP:\n",
      "  id              title            type\n",
      "0  2      Project Alpha        projects\n",
      "1  3  investigation one  investigations\n",
      "2  3          study one         studies\n",
      "\n",
      "ISA STRUCTURE DOWN:\n",
      "   id          title        type\n",
      "0  38  Network Image  data_files\n",
      "\n",
      "ISA STRUCTURE PEOPLE:\n",
      "  id          title       type\n",
      "0  1  Dorotea Dudas   creators\n",
      "1  1  Dorotea Dudas  submitter\n",
      "2  1  Dorotea Dudas     people\n",
      "\n",
      "OUTPUT:\n",
      "    id          title        type\n",
      "0  38  Network Image  data_files \n",
      "\n",
      "FILE: \n",
      "Name of 'data_files': New Pink Image\n",
      "\n",
      "RELATIONSHIPS: \n",
      "\n",
      "6 relationships found: \n",
      "\n",
      "  id                      title            type\n",
      "0  1              Dorotea Dudas       submitter\n",
      "1  1              Dorotea Dudas          people\n",
      "2  2              Project Alpha        projects\n",
      "3  3          investigation one  investigations\n",
      "4  3                  study one         studies\n",
      "5  3  assay linked to data file          assays\n",
      "\n",
      "ISA STRUCTURE: \n",
      "ISA STRUCTURE UP:\n",
      "  id                      title            type\n",
      "0  2              Project Alpha        projects\n",
      "1  3          investigation one  investigations\n",
      "2  3                  study one         studies\n",
      "3  3  assay linked to data file          assays\n",
      "\n",
      "ISA STRUCTURE PEOPLE:\n",
      "  id          title       type\n",
      "0  1  Dorotea Dudas  submitter\n",
      "1  1  Dorotea Dudas     people\n",
      "\n",
      "OUTPUT: empty \n",
      "\n",
      "FILE: \n",
      "Name of 'data_files': Network Image\n",
      "\n",
      "RELATIONSHIPS: \n",
      "\n",
      "8 relationships found: \n",
      "\n",
      "  id               title            type\n",
      "0  3       Teodora Dudas        creators\n",
      "1  1       Dorotea Dudas       submitter\n",
      "2  1       Dorotea Dudas          people\n",
      "3  3       Teodora Dudas          people\n",
      "4  2       Project Alpha        projects\n",
      "5  3   investigation one  investigations\n",
      "6  3           study one         studies\n",
      "7  4  Assay to be copied          assays\n",
      "\n",
      "ISA STRUCTURE: \n",
      "ISA STRUCTURE UP:\n",
      "  id               title            type\n",
      "0  2       Project Alpha        projects\n",
      "1  3   investigation one  investigations\n",
      "2  3           study one         studies\n",
      "3  4  Assay to be copied          assays\n",
      "\n",
      "ISA STRUCTURE PEOPLE:\n",
      "  id          title       type\n",
      "0  3  Teodora Dudas   creators\n",
      "1  1  Dorotea Dudas  submitter\n",
      "2  1  Dorotea Dudas     people\n",
      "3  3  Teodora Dudas     people\n",
      "\n",
      "OUTPUT: empty \n",
      "\n",
      "Name of 'studies': study one\n",
      "\n",
      "Registered study:  {'data': {'id': '11', 'type': 'studies', 'attributes': {'policy': {'access': 'no_access', 'permissions': [{'resource': {'id': '2', 'type': 'projects'}, 'access': 'download'}]}, 'title': 'study one', 'description': 'the description of study', 'experimentalists': None, 'other_creators': None, 'person_responsible_id': None}, 'relationships': {'creators': {'data': [{'id': '1', 'type': 'people'}]}, 'submitter': {'data': [{'id': '1', 'type': 'people'}]}, 'people': {'data': [{'id': '1', 'type': 'people'}]}, 'projects': {'data': [{'id': '2', 'type': 'projects'}]}, 'investigation': {'data': {'id': '4', 'type': 'investigations'}}, 'assays': {'data': []}, 'data_files': {'data': []}, 'models': {'data': []}, 'sops': {'data': []}, 'publications': {'data': []}, 'documents': {'data': []}}, 'links': {'self': '/studies/11'}, 'meta': {'created': '2019-04-30T12:09:18.760Z', 'modified': '2019-04-30T12:09:18.721Z', 'api_version': '0.1', 'uuid': 'b463bfe0-4d6e-0137-77ae-10e7c619e7b6', 'base_url': 'http://localhost:4000'}}, 'jsonapi': {'version': '1.0'}}\n",
      "Name of 'assays': assay linked to data file\n",
      "\n",
      "Registered assay:  {'data': {'id': '21', 'type': 'assays', 'attributes': {'policy': {'access': 'no_access', 'permissions': [{'resource': {'id': '2', 'type': 'projects'}, 'access': 'download'}]}, 'title': 'assay linked to data file', 'description': 'the description of assay', 'other_creators': None, 'assay_class': {'title': 'Experimental assay', 'key': 'EXP', 'description': None}, 'assay_type': {'label': 'Metabolomics', 'uri': 'http://jermontology.org/ontology/JERMOntology#Metabolomics'}, 'technology_type': {'label': 'Electrophoresis', 'uri': 'http://jermontology.org/ontology/JERMOntology#Electrophoresis'}, 'tags': None}, 'relationships': {'creators': {'data': [{'id': '1', 'type': 'people'}]}, 'submitter': {'data': [{'id': '1', 'type': 'people'}]}, 'organisms': {'data': []}, 'people': {'data': [{'id': '1', 'type': 'people'}]}, 'projects': {'data': [{'id': '2', 'type': 'projects'}]}, 'investigation': {'data': {'id': '4', 'type': 'investigations'}}, 'study': {'data': {'id': '11', 'type': 'studies'}}, 'data_files': {'data': []}, 'models': {'data': []}, 'sops': {'data': []}, 'publications': {'data': []}, 'documents': {'data': []}}, 'links': {'self': '/assays/21'}, 'meta': {'created': '2019-04-30T12:09:20.224Z', 'modified': '2019-04-30T12:09:20.210Z', 'api_version': '0.1', 'uuid': 'b5472030-4d6e-0137-77ae-10e7c619e7b6', 'base_url': 'http://localhost:4000'}}, 'jsonapi': {'version': '1.0'}}\n",
      "Registered data_file:  {'id': '61', 'type': 'data_files', 'attributes': {'policy': {'access': 'no_access', 'permissions': [{'resource': {'id': '2', 'type': 'projects'}, 'access': 'download'}]}, 'title': 'New Pink Image', 'description': None, 'license': 'CC-BY-4.0', 'latest_version': 1, 'tags': None, 'versions': [{'version': 1, 'revision_comments': None, 'url': 'http://localhost:4000/data_files/61?version=1'}], 'version': 1, 'revision_comments': None, 'created_at': '2019-04-30T12:09:22.000Z', 'updated_at': '2019-04-30T12:09:22.000Z', 'content_blobs': [{'original_filename': 'logo.png', 'url': None, 'md5sum': None, 'sha1sum': None, 'content_type': 'image/png', 'link': 'http://localhost:4000/data_files/61/content_blobs/64', 'size': None}], 'other_creators': None}, 'relationships': {'creators': {'data': [{'id': '1', 'type': 'people'}]}, 'submitter': {'data': [{'id': '1', 'type': 'people'}]}, 'people': {'data': [{'id': '1', 'type': 'people'}]}, 'projects': {'data': [{'id': '2', 'type': 'projects'}]}, 'investigations': {'data': [{'id': '4', 'type': 'investigations'}]}, 'studies': {'data': [{'id': '11', 'type': 'studies'}]}, 'assays': {'data': [{'id': '21', 'type': 'assays'}]}, 'publications': {'data': []}, 'events': {'data': []}}, 'links': {'self': '/data_files/61?version=1'}, 'meta': {'created': '2019-04-30T12:09:22.582Z', 'modified': '2019-04-30T12:09:22.567Z', 'api_version': '0.1', 'uuid': 'b6aefa00-4d6e-0137-77ae-10e7c619e7b6', 'base_url': 'http://localhost:4000'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded blob data:  [{'original_filename': 'logo.png', 'url': None, 'md5sum': 'f60285d71f41c0ca0a31861bd42b3aac', 'sha1sum': 'd91e7415d4f0858436bdb1d659ccc5ddfb361ef2', 'content_type': 'image/png', 'link': 'http://localhost:4000/data_files/61/content_blobs/64', 'size': 7665}]\n",
      "Name of 'assays': Assay to be copied\n",
      "\n",
      "Registered assay:  {'data': {'id': '22', 'type': 'assays', 'attributes': {'policy': {'access': 'no_access', 'permissions': [{'resource': {'id': '2', 'type': 'projects'}, 'access': 'download'}]}, 'title': 'Assay to be copied', 'description': 'Description of an assay to be copied.', 'other_creators': None, 'assay_class': {'title': 'Experimental assay', 'key': 'EXP', 'description': None}, 'assay_type': {'label': 'Experimental Assay Type', 'uri': 'http://jermontology.org/ontology/JERMOntology#Experimental_assay_type'}, 'technology_type': {'label': 'Technology Type', 'uri': 'http://jermontology.org/ontology/JERMOntology#Technology_type'}, 'tags': None}, 'relationships': {'creators': {'data': [{'id': '1', 'type': 'people'}]}, 'submitter': {'data': [{'id': '1', 'type': 'people'}]}, 'organisms': {'data': []}, 'people': {'data': [{'id': '1', 'type': 'people'}]}, 'projects': {'data': [{'id': '2', 'type': 'projects'}]}, 'investigation': {'data': {'id': '4', 'type': 'investigations'}}, 'study': {'data': {'id': '11', 'type': 'studies'}}, 'data_files': {'data': []}, 'models': {'data': []}, 'sops': {'data': []}, 'publications': {'data': []}, 'documents': {'data': []}}, 'links': {'self': '/assays/22'}, 'meta': {'created': '2019-04-30T12:09:24.484Z', 'modified': '2019-04-30T12:09:24.464Z', 'api_version': '0.1', 'uuid': 'b7d0c9e0-4d6e-0137-77ae-10e7c619e7b6', 'base_url': 'http://localhost:4000'}}, 'jsonapi': {'version': '1.0'}}\n",
      "Registered data_file:  {'id': '62', 'type': 'data_files', 'attributes': {'policy': {'access': 'no_access', 'permissions': [{'resource': {'id': '2', 'type': 'projects'}, 'access': 'download'}]}, 'title': 'Network Image', 'description': None, 'license': 'CC-BY-4.0', 'latest_version': 1, 'tags': None, 'versions': [{'version': 1, 'revision_comments': None, 'url': 'http://localhost:4000/data_files/62?version=1'}], 'version': 1, 'revision_comments': None, 'created_at': '2019-04-30T12:09:26.000Z', 'updated_at': '2019-04-30T12:09:26.000Z', 'content_blobs': [{'original_filename': 'image_02.png', 'url': None, 'md5sum': None, 'sha1sum': None, 'content_type': 'image/png', 'link': 'http://localhost:4000/data_files/62/content_blobs/65', 'size': None}], 'other_creators': None}, 'relationships': {'creators': {'data': [{'id': '1', 'type': 'people'}]}, 'submitter': {'data': [{'id': '1', 'type': 'people'}]}, 'people': {'data': [{'id': '1', 'type': 'people'}]}, 'projects': {'data': [{'id': '2', 'type': 'projects'}]}, 'investigations': {'data': [{'id': '4', 'type': 'investigations'}]}, 'studies': {'data': [{'id': '11', 'type': 'studies'}]}, 'assays': {'data': [{'id': '22', 'type': 'assays'}]}, 'publications': {'data': []}, 'events': {'data': []}}, 'links': {'self': '/data_files/62?version=1'}, 'meta': {'created': '2019-04-30T12:09:26.132Z', 'modified': '2019-04-30T12:09:26.115Z', 'api_version': '0.1', 'uuid': 'b8cca730-4d6e-0137-77ae-10e7c619e7b6', 'base_url': 'http://localhost:4000'}}\n",
      "Uploaded blob data:  [{'original_filename': 'image_02.png', 'url': None, 'md5sum': '8b614ae8a242fe8419099b6f77a9c9e5', 'sha1sum': '2898b02b0dfd0dd6615c555ec15ba0744a08b9ef', 'content_type': 'image/png', 'link': 'http://localhost:4000/data_files/62/content_blobs/65', 'size': 140675}]\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "registerAndCopyStudyAndBelow(session1, session2, headers1, headers2, headers3, \n",
    "                    source_base_url, source_json_id, source_data_type, #source_json, \n",
    "                    target_base_url, target_project_id, target_investigation_id, target_creator_id)#, isa_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DELETE THE COPIED ISA STRUCTURE (USING the output from getFullDISA())\n",
    "def deleteISA(session, headers_json, base_url, data_id, data_type):\n",
    "    \n",
    "    ### GET DISA FROM COPIED DATA (could also use output from getDISA)\n",
    "    isa_structure = getFullDISA(session, headers_json, base_url, data_id, data_type)\n",
    "    \n",
    "    for x in reversed(range(0, len(isa_structure))):  \n",
    "        #print(isa_structure[x][0])\n",
    "        print(isa_structure[x][0]['type'], isa_structure[x][0]['id'])\n",
    "        \n",
    "        ### READ JSON TO GET THE LINK FOR DELETION\n",
    "        json_entry = json_for_resource(session, headers_json, base_url, isa_structure[x][0]['type'], isa_structure[x][0]['id'])\n",
    "        \n",
    "        ### LINK TO ENTRY \n",
    "        json_entry_url = json_entry['data']['links']['self']\n",
    "        \n",
    "        ### DELETE ENTRY\n",
    "        session.delete(base_url + json_entry_url)\n",
    "        \n",
    "    print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE: \n",
      "Name of 'studies': study one\n",
      "\n",
      "RELATIONSHIPS: \n",
      "\n",
      "9 relationships found: \n",
      "\n",
      "   id                      title            type\n",
      "0   1              Dorotea Dudas        creators\n",
      "1   1              Dorotea Dudas       submitter\n",
      "2   1              Dorotea Dudas          people\n",
      "3   2              Project Alpha        projects\n",
      "4   4          investigation two  investigations\n",
      "5  21  assay linked to data file          assays\n",
      "6  22         Assay to be copied          assays\n",
      "7  61             New Pink Image      data_files\n",
      "8  62              Network Image      data_files\n",
      "\n",
      "ISA STRUCTURE: \n",
      "ISA STRUCTURE UP:\n",
      "  id              title            type\n",
      "0  2      Project Alpha        projects\n",
      "1  4  investigation two  investigations\n",
      "\n",
      "ISA STRUCTURE DOWN:\n",
      "   id                      title        type\n",
      "0  21  assay linked to data file      assays\n",
      "1  22         Assay to be copied      assays\n",
      "2  61             New Pink Image  data_files\n",
      "3  62              Network Image  data_files\n",
      "\n",
      "ISA STRUCTURE PEOPLE:\n",
      "  id          title       type\n",
      "0  1  Dorotea Dudas   creators\n",
      "1  1  Dorotea Dudas  submitter\n",
      "2  1  Dorotea Dudas     people\n",
      "\n",
      "FILE: \n",
      "Name of 'assays': assay linked to data file\n",
      "\n",
      "RELATIONSHIPS: \n",
      "\n",
      "7 relationships found: \n",
      "\n",
      "   id              title            type\n",
      "0   1      Dorotea Dudas        creators\n",
      "1   1      Dorotea Dudas       submitter\n",
      "2   1      Dorotea Dudas          people\n",
      "3   2      Project Alpha        projects\n",
      "4   4  investigation two  investigations\n",
      "5  11          study one         studies\n",
      "6  61     New Pink Image      data_files\n",
      "\n",
      "ISA STRUCTURE: \n",
      "ISA STRUCTURE UP:\n",
      "   id              title            type\n",
      "0   2      Project Alpha        projects\n",
      "1   4  investigation two  investigations\n",
      "2  11          study one         studies\n",
      "\n",
      "ISA STRUCTURE DOWN:\n",
      "   id           title        type\n",
      "0  61  New Pink Image  data_files\n",
      "\n",
      "ISA STRUCTURE PEOPLE:\n",
      "  id          title       type\n",
      "0  1  Dorotea Dudas   creators\n",
      "1  1  Dorotea Dudas  submitter\n",
      "2  1  Dorotea Dudas     people\n",
      "\n",
      "OUTPUT:\n",
      "    id           title        type\n",
      "0  61  New Pink Image  data_files \n",
      "\n",
      "FILE: \n",
      "Name of 'assays': Assay to be copied\n",
      "\n",
      "RELATIONSHIPS: \n",
      "\n",
      "7 relationships found: \n",
      "\n",
      "   id              title            type\n",
      "0   1      Dorotea Dudas        creators\n",
      "1   1      Dorotea Dudas       submitter\n",
      "2   1      Dorotea Dudas          people\n",
      "3   2      Project Alpha        projects\n",
      "4   4  investigation two  investigations\n",
      "5  11          study one         studies\n",
      "6  62      Network Image      data_files\n",
      "\n",
      "ISA STRUCTURE: \n",
      "ISA STRUCTURE UP:\n",
      "   id              title            type\n",
      "0   2      Project Alpha        projects\n",
      "1   4  investigation two  investigations\n",
      "2  11          study one         studies\n",
      "\n",
      "ISA STRUCTURE DOWN:\n",
      "   id          title        type\n",
      "0  62  Network Image  data_files\n",
      "\n",
      "ISA STRUCTURE PEOPLE:\n",
      "  id          title       type\n",
      "0  1  Dorotea Dudas   creators\n",
      "1  1  Dorotea Dudas  submitter\n",
      "2  1  Dorotea Dudas     people\n",
      "\n",
      "OUTPUT:\n",
      "    id          title        type\n",
      "0  62  Network Image  data_files \n",
      "\n",
      "FILE: \n",
      "Name of 'data_files': New Pink Image\n",
      "\n",
      "RELATIONSHIPS: \n",
      "\n",
      "7 relationships found: \n",
      "\n",
      "   id                      title            type\n",
      "0   1              Dorotea Dudas        creators\n",
      "1   1              Dorotea Dudas       submitter\n",
      "2   1              Dorotea Dudas          people\n",
      "3   2              Project Alpha        projects\n",
      "4   4          investigation two  investigations\n",
      "5  11                  study one         studies\n",
      "6  21  assay linked to data file          assays\n",
      "\n",
      "ISA STRUCTURE: \n",
      "ISA STRUCTURE UP:\n",
      "   id                      title            type\n",
      "0   2              Project Alpha        projects\n",
      "1   4          investigation two  investigations\n",
      "2  11                  study one         studies\n",
      "3  21  assay linked to data file          assays\n",
      "\n",
      "ISA STRUCTURE PEOPLE:\n",
      "  id          title       type\n",
      "0  1  Dorotea Dudas   creators\n",
      "1  1  Dorotea Dudas  submitter\n",
      "2  1  Dorotea Dudas     people\n",
      "\n",
      "OUTPUT: empty \n",
      "\n",
      "FILE: \n",
      "Name of 'data_files': Network Image\n",
      "\n",
      "RELATIONSHIPS: \n",
      "\n",
      "7 relationships found: \n",
      "\n",
      "   id               title            type\n",
      "0   1       Dorotea Dudas        creators\n",
      "1   1       Dorotea Dudas       submitter\n",
      "2   1       Dorotea Dudas          people\n",
      "3   2       Project Alpha        projects\n",
      "4   4   investigation two  investigations\n",
      "5  11           study one         studies\n",
      "6  22  Assay to be copied          assays\n",
      "\n",
      "ISA STRUCTURE: \n",
      "ISA STRUCTURE UP:\n",
      "   id               title            type\n",
      "0   2       Project Alpha        projects\n",
      "1   4   investigation two  investigations\n",
      "2  11           study one         studies\n",
      "3  22  Assay to be copied          assays\n",
      "\n",
      "ISA STRUCTURE PEOPLE:\n",
      "  id          title       type\n",
      "0  1  Dorotea Dudas   creators\n",
      "1  1  Dorotea Dudas  submitter\n",
      "2  1  Dorotea Dudas     people\n",
      "\n",
      "OUTPUT: empty \n",
      "\n",
      "data_files 62\n",
      "data_files 61\n",
      "assays 22\n",
      "assays 21\n",
      "studies 11\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "deleteISA(session2, headers1, target_base_url, 11, 'studies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Close the HTTP **session**\"\"\"\n",
    "session.close()\n",
    "session2.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
